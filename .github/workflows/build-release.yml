name: "Build and Release"

on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  pull_request:
    branches: [ main ]

permissions:
  contents: write
  packages: write

env:
  CARGO_TERM_COLOR: always

jobs:
  test-tauri:
    strategy:
      fail-fast: false
      matrix:
        include:
          - platform: 'macos-latest' # for Arm based macs (M1 and above).
            args: '--target aarch64-apple-darwin'
          - platform: 'macos-latest' # for Intel based macs.
            args: '--target x86_64-apple-darwin'
          - platform: 'ubuntu-22.04' # for Tauri v1 you could use ubuntu-20.04.
            args: ''
          - platform: 'windows-latest'
            args: ''

    runs-on: ${{ matrix.platform }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies (ubuntu only)
        if: matrix.platform == 'ubuntu-22.04'
        run: |
          sudo apt-get update
          sudo apt-get install -y libwebkit2gtk-4.0-dev libwebkit2gtk-4.1-dev libappindicator3-dev librsvg2-dev patchelf

      - name: Rust setup
        uses: dtolnay/rust-toolchain@stable
        with:
          # Those targets are only used on macos runners so it's in an `if` to slightly speed up the ubuntu and windows builds.
          targets: ${{ matrix.platform == 'macos-latest' && 'aarch64-apple-darwin,x86_64-apple-darwin' || '' }}

      - name: Rust cache
        uses: swatinem/rust-cache@v2
        with:
          workspaces: './src-tauri -> target'

      - name: Sync node version and setup cache
        uses: actions/setup-node@v4
        with:
          node-version: 'lts/*'
          cache: 'npm'

      - name: Install frontend dependencies
        shell: bash
        run: |
          echo "Installing frontend dependencies..."
          npm ci || {
            echo "npm ci failed, trying npm install..."
            npm install || {
              echo "Both npm ci and npm install failed"
              echo "Package.json contents:"
              cat package.json
              exit 1
            }
          }
          echo "Frontend dependencies installed"

      - name: Build frontend
        shell: bash
        run: |
          echo "Building frontend for release..."
          npm run build || {
            echo "Frontend build failed"
            echo "Node version: $(node --version)"
            echo "NPM version: $(npm --version)"
            echo "Environment variables:"
            env | grep -E "NODE_|NPM_" || echo "No Node/NPM env vars"
            exit 1
          }
          echo "Frontend build successful"
          
          # Validate build output
          if [ -d "dist" ]; then
            echo "Build output size:"
            du -sh dist/ 2>/dev/null || echo "Could not determine size"
            echo "Build files:"
            find dist/ -type f 2>/dev/null | head -10 || ls dist/ | head -10
          else
            echo "dist directory not found"
          fi

      - name: Build Tauri app
        uses: tauri-apps/tauri-action@v0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tagName: ${{ github.ref_name }}
          releaseName: 'Offline Medical Assistant v__VERSION__'
          releaseBody: |
            ## 🏥 Offline Medical Assistant v__VERSION__
            
            **Privacy-focused medical AI assistant for offline consultations**
            
            ### ✨ What's New in This Release
            - Complete offline medical AI assistant
            - Local data storage for privacy protection
            - Cross-platform desktop application
            - Integrated Ollama AI for medical guidance
            - Real-time chat with medical AI models
            - Conversation history and management
            - Configurable AI settings and model selection
            
            ### 📥 Installation Instructions
            
            #### Prerequisites
            1. **Install Ollama**: Download from [ollama.ai](https://ollama.ai)
            2. **Pull a medical model**: Run `ollama pull llama3.1:8b` or `ollama pull mixtral:8x7b`
            3. **Ensure Ollama is running**: Start Ollama service before using the app
            
            #### Platform-Specific Installation
            
            **🪟 Windows**
            - Download the `.msi` installer
            - Run the installer with administrator privileges
            - The app will be available in Start Menu
            
            **🍎 macOS**
            - **Intel Macs**: Download the `.dmg` file
            - **Apple Silicon (M1/M2)**: Download the `.app.tar.gz` file
            - For .dmg: Mount and drag to Applications folder
            - For .app.tar.gz: Extract and move to Applications folder
            
            **🐧 Linux**
            - **AppImage**: Download, make executable (`chmod +x`), and run
            - **Debian/Ubuntu**: Download `.deb` and install with `sudo dpkg -i filename.deb`
            
            ### ⚠️ Medical Disclaimer
            **IMPORTANT**: This application provides educational information and guidance only. It is NOT a substitute for professional medical advice, diagnosis, or treatment. Always seek the advice of qualified healthcare providers with any questions regarding medical conditions. Never disregard professional medical advice or delay seeking treatment based on information from this application.
            
            ### 🔒 Privacy Features
            - **100% Offline**: No data leaves your device
            - **Local Storage**: All conversations stored locally in SQLite
            - **No Telemetry**: Zero tracking or analytics
            - **HIPAA Considerations**: Designed with healthcare privacy in mind
            
            ### 🛠️ Technical Requirements
            - **RAM**: Minimum 4GB (8GB recommended)
            - **Storage**: 2GB free space
            - **Ollama**: Must be installed and running
            - **Models**: At least one language model pulled in Ollama
            
            ### 📋 Platform Downloads
            - **Windows**: `.msi` installer (x64)
            - **macOS Intel**: `.dmg` package
            - **macOS Apple Silicon**: `.app.tar.gz` package
            - **Linux**: `.AppImage` (portable) or `.deb` (Debian/Ubuntu)
            
            ### 🔗 Useful Links
            - [Installation Guide](./RELEASE_GUIDE.md)
            - [Troubleshooting](./README.md#troubleshooting)
            - [Ollama Documentation](https://ollama.ai/docs)
            
            ---
            
            **Built with**: React + TypeScript, Tauri, Rust, SQLite, Ollama
            **License**: Privacy-focused medical software
            
            See full changelog and technical documentation in the repository.
          releaseDraft: false
          prerelease: ${{ contains(github.ref_name, 'beta') || contains(github.ref_name, 'alpha') }}
          args: ${{ matrix.args }}

  # Separate job for updating version and creating release
  create-release:
    if: startsWith(github.ref, 'refs/tags/v')
    needs: test-tauri
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Get version from tag
        id: version
        run: echo "VERSION=${GITHUB_REF#refs/tags/v}" >> $GITHUB_OUTPUT

      - name: Update CHANGELOG
        run: |
          echo "## [${VERSION}] - $(date +%Y-%m-%d)" >> CHANGELOG_NEW.md
          echo "" >> CHANGELOG_NEW.md
          echo "### Added" >> CHANGELOG_NEW.md
          echo "- Release version ${VERSION}" >> CHANGELOG_NEW.md
          echo "" >> CHANGELOG_NEW.md
          if [ -f CHANGELOG.md ]; then
            cat CHANGELOG.md >> CHANGELOG_NEW.md
          fi
          mv CHANGELOG_NEW.md CHANGELOG.md
        env:
          VERSION: ${{ steps.version.outputs.VERSION }}

      - name: Commit changelog
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add CHANGELOG.md
          git commit -m "Update CHANGELOG for v${VERSION}" || exit 0
          git push || exit 0
        env:
          VERSION: ${{ steps.version.outputs.VERSION }}
